---
title: "CompulsoryExercise2"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries,eval=FALSE,include=FALSE}
#install.packages("knitr") #probably already installed
#install.packages("rmarkdown") #probably already installed
#install.packages("ggplot2") #plotting with ggplot
#install.packages("ggfortify")
#install.packages("leaps")
#install.packages("glmnet")
#install.packages("tree")
#install.packages("caret")
#install.packages("randomForest")
#install.packages("readr")
#install.packages("e1071")
#install.packages("dplyr")
#install.packages("crop")
#install.packages("rpart")
library(knitr)
library(rmarkdown)
library(ggplot2)
library(ggfortify)
library(leaps)
library(glmnet)
library(tree)
library(caret)
library(randomForest)
library(readr)
library(e1071)
library(dplyr)
library(crop)
library(rpart)
```


## Problem 1


### A)

1. True
2. True
3. True
4. False


### B)

```{r load data, include=TRUE}
id <- "1iI6YaqgG0QJW5onZ_GTBsCvpKPExF30G" # google file ID
catdat <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download", id),header=T)


set.seed(4268)
train.ind = sample(1:nrow(catdat), 0.5*nrow(catdat))
catdat.train = catdat[train.ind,]
catdat.test = catdat[-train.ind,]
regfit_full <- regsubsets(birds~., data = catdat.train)
reg_summary <- summary(regfit_full)
reg_summary
```


```{r plot, include=TRUE}


par(mfrow=c(2,2))
min_rss <- which.min(reg_summary$rss)
plot(reg_summary$rss ,xlab="Number of Variables",ylab="RSS",type="l")
points(min_rss,reg_summary$rss[min_rss], col="red",cex=2,pch=20)
plot(reg_summary$adjr2 ,xlab="Number of Variables",ylab="Adjusted RSq",type="l")
max_adj <- which.max(reg_summary$adjr2)
points(max_adj,reg.summary$adjr2[max_adj], col="red",cex=2,pch=20)
plot(reg_summary$cp ,xlab="Number of Variables",ylab="Cp",type="l")
min_cp <- which.min(reg_summary$cp )
points(min_cp,reg_summary$cp [min_cp],col="red",cex=2,pch=20)
min_bic <- which.min(reg.summary$bic)
plot(reg_summary$bic ,xlab="Number of Variables",ylab="BIC",type="l")
points(min_bic,reg_summary$bic [min_bic],col="red",cex=2,pch=20)
```

```{r s, include=TRUE}
plot(regfit.full, scale="bic")
```
To decide the best subset of variables, we use the Bayesian information criteria.The reason we use BIC and not R squared, is that BIC penalizes the number of parameters in the model. If we want to use a subset of the variables, it is therefore better to use BIC. We can see from the plots that the best model has only six variables, which are wetfood, daily playtime, children, urban, bell and daily outdoortime.

```{r 2, include=TRUE}
regfit.best <- regsubsets(birds ~ ., data = catdat.test)
test.mat = model.matrix(birds ~ ., data=catdat.train)

val.errors=rep(NA,8)
for(i in 1:8){
  coefi=coef(regfit.best,id=i)
  pred=test.mat[,names(coefi)]%*%coefi
  val.errors[i]=mean((catdat.test$birds-pred)^2)
}

val.errors
```

### C)

```{r k, include=TRUE}
x.train <- model.matrix(birds~., data = catdat.train)[,-1]
y.train <- catdat.train$birds
x.test = model.matrix(birds~., data = catdat.test)[,-1]
y.test = catdat.test$birds
```

```{r, include=TRUE}
set.seed(1)
grid=10^seq(10,-2,length=100)
lasso.mod = glmnet(x.train, y.train, alpha=1, lambda = grid)
plot(lasso.mod)

cv.out=cv.glmnet(x.train,y.train,alpha=1)
plot(cv.out)
bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod,s=bestlam ,newx=x.test)
mse = mean((lasso.pred-y.test)^2)
cat("The MSE for the lasso regression model are ", mse, "\n")
out=glmnet(x.test,y.test,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:18,]
print("The non zero coefficients are:")
lasso.coef[lasso.coef!=0]
```

### D)
The tuning parameter serves the purpose of controlling the RSS and the shrinkage penalty, $\lambda \sum \beta^2_j$. When $\lambda \rightarrow \infty$, the ridge regression coefficients estimates will approach zero, since the impact the of the shrinkage penalty increases. When the tuning parameter is zero, ridge regression is the same as RSS, since the shrinkage penalty has no effect.

### E)

### F)


## Problem 2.

### A) 
 
1. True
2. False (Litt usikker)
3. False (https://www.math.ntnu.no/emner/TMA4268/2018v/7BeyondLinear/7.pdf)
4. False

### B)

One way of representing a cubic spline is to use $x, x^2, x^3$ and then add one trucated power basis function per knot. 

The truncated power basis function is defined as $h(x,\xi) = (x-\xi)^3_+$ if x is greater than $\xi$ and 0 otherwise.  

This gives us the basis functions $x, x^2, x^3, (x-q_1)^3, (x-q_2)^3$

### C)

```{r, include=TRUE}
for(i in 1:10){
  model <- lm(birds ~ poly(daily.outdoortime, i), data = catdat.train)
  predictions <- model %>% predict(catdat.train)
  plot(predictions)
}
```



## Problem 3.

### A)

1. False
2. True
3. True
4. False

## B)
By looking at the tree above, we can conclude that we will have two nodes left, which are age < 81.5, and country: indonesia, japan, Korea. This will give us three leaves, two for the split between countries, and one for the split between age. The reason we are left with age and country as nodes, are that they have more observations than age < 46.5. When building a regression tree, 

## C)

```{r}
id <- "1Fv6xwKLSZHldRAC1MrcK2mzdOYnbgv0E" # google file ID
d.diabetes <- dget(sprintf("https://docs.google.com/uc?id=%s&export=download", id))
d.train=d.diabetes$ctrain
d.test=d.diabetes$ctest
```

```{r, include=TRUE}
set.seed(1)
t.diabetes <- tree(diabetes ~ . , data=d.train)
#plot(t.diabetes)
#text(t.diabetes)
#title(main = "Unpruned Classification Tree")

cv.diabetes=cv.tree(t.diabetes, FUN = prune.misclass)
plot(cv.diabetes$size,cv.diabetes$dev,type="b",
                   xlab="Terminal nodes")

#par(mfrow = c(1, 2))
# default plot
#plot(cv.diabetes)
# better plot
#plot(cv.diabetes$size, cv.diabetes$dev / nrow(cv.diabetes), type = "b",
    # xlab = "Tree Size", ylab = "CV Misclassification Rate")
```

```{r, include=TRUE}
set.seed(1)
```
```{r cars}
summary(cars)
```


# Problem 4
## 4A)
### i)
#### TODO:
### ii)
#### TODO:
### iii)
#### TODO:
### iv)
#### TODO:

## 4B)

```{r task4b_data}
library(e1071)

id <- "1x_E8xnmz9CMHh_tMwIsWP94czPa1Fpsj"  # google file ID
d.leukemia <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download", id), header = T)

set.seed(2399)
t.samples <- sample(1:60, 15, replace = F)
d.leukemia$Category <- as.factor(d.leukemia$Category)
d.leukemia.test <- d.leukemia[t.samples, ]
d.leukemia.train <- d.leukemia[-t.samples, ]
```

### i)
### TODO: Why is a SVM more suitable than logistic regression. What to use instead?
### ii)
The paper proposes an ensamble SVM for gene selection.
### TODO: Add one more sentence above.
### iii)
```{r task4biii}
svmfit=svm(Category~., data=d.leukemia.train, kernel="linear", cost=1, scale=TRUE)
summary(svmfit)

pred.train<-predict(svmfit, d.leukemia.train)
pred.test<-predict(svmfit, d.leukemia.test)

table(pred.train, d.leukemia.train$Category)
sum(pred.train!=d.leukemia.train$Category)/length(pred.train)
table(pred.test, d.leukemia.test$Category)
sum(pred.test!=d.leukemia.test$Category)/length(pred.test)
```
From the above code-snippet we see that the error rate for the training set was 0% and
for the test set it was 26.67%. 
No, it is not surprising to see that the misclassification rate on the training set
is 0%, as there are so many features compared to the number of and the data is thus
probably linearly seprable.
The most common type of error that we see in the test set are type 2 errors.
The sensitivity in this case is 0.333, which is very low and the classification
method is not successful.

#The most common error type in the test set is type 2 errors: there are 4 persons that
#are classified as Non-Relapse, that relapsed.
#No, the classification method is not successful as it has a sensitivity of 0.2, which is
#not good.

### iv)

```{r task4biv_0.00001}
svmfit_radial=svm(Category~., data=d.leukemia.train, kernel="radial", cost=1, scale=TRUE, gamma=0.00001, na.action=na.omit)
pred.train<-predict(svmfit_radial, d.leukemia.train)
table(pred.train, d.leukemia.train$Category)
pred.test<-predict(svmfit_radial, d.leukemia.test)
table(pred.test, d.leukemia.test$Category)
sum(pred.test!=d.leukemia.test$Category)/length(pred.test)
summary(svmfit_radial)
```

```{r task4biv_0.01}
svmfit_radial=svm(Category~., data=d.leukemia.train, kernel="radial", cost=1, scale=TRUE, gamma=0.01, na.action=na.omit)
pred.train<-predict(svmfit_radial, d.leukemia.train)
table(pred.train, d.leukemia.train$Category)
pred.test<-predict(svmfit_radial, d.leukemia.test)
table(pred.test, d.leukemia.test$Category)
sum(pred.test!=d.leukemia.test$Category)/length(pred.test)
summary(svmfit_radial)
```
# TODO: Interpret results.
## (small values of gamma is high bias - low variance)
## 4C)

### TODO: Use rmd, it is done on paper.

# Problem 5
## 5A)
### i)
True
### ii)
False
### iii)
False
### iv)
False

## 5B)
```{r task5_handout}
x1 <- c(1, 2, 0, 4, 5, 6)
x2 <- c(5, 4, 3, 1, 1, 2)
```

### i)
```{r task5bi}
set.seed(1)
clusters<-sample(c(1,2), size=length(x1), replace=TRUE)
clusters

plot(x1, x2, col=clusters, pch=19, main="clustering")
legend("topleft", legend=c("1", "2"), col=c("black", "red"), bty="o", cex=0.8, pch=19)
```

## ii)
```{r task5bii}
center.1<-c(
  sum(x1[clusters==1])/length(x1[clusters==1]),
  sum(x2[clusters==1])/length(x2[clusters==1]))
center.1
center.2<-c(
  sum(x1[clusters==2])/length(x1[clusters==2]),
  sum(x2[clusters==2])/length(x2[clusters==2]))
center.2

plot(x1, x2, col=clusters, pch=19, main="clustering")
points(center.1[1], center.1[2], col="gray", pch=19)
points(center.2[1], center.2[2], col="darkred", pch=19)
legend("bottomleft", legend=c("1", "2", "center 1", "center 2"), col=c("black", "red", "gray", "darkred"), bty="o", cex=0.8, pch=19)
```


## iii)
```{r task5biii}
euc_dist<-function(a, b) sqrt(sum((a-b)^2))
points<-matrix(c(x1, x2), nrow=length(x1), ncol=2, byrow=FALSE)
clusters<-apply(points, 1, function(point) ifelse(euc_dist(point, center.1) < euc_dist(point, center.2),1, 2))

plot(x1, x2, col=clusters, pch=19, main="clustering")
legend("topleft", legend=c("1", "2"), col=c("black", "red"), bty="o", cex=0.8, pch=19)
```


# Task 5c

```{r task5chandout}
id <- "1VfVCQvWt121UN39NXZ4aR9Dmsbj-p9OU"  # google file ID
GeneData <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download", 
                             id), header = F)
colnames(GeneData)[1:20] = paste(rep("H", 20), c(1:20), sep = "")
colnames(GeneData)[21:40] = paste(rep("D", 20), c(1:20), sep = "")
row.names(GeneData) = paste(rep("G", 1000), c(1:1000), sep = "")
GeneData = t(GeneData)
GeneData <- scale(GeneData)
```

```{r task5c}
par(mfrow=c(2,3))
euc_dists<-dist(GeneData)
plot(hclust(euc_dists, method="complete"), main="Complete linkage with euclidian distance")
plot(hclust(euc_dists, method="single"), main="Single linkage with euclidian distance")
plot(hclust(euc_dists, method="average"), main="Average linkage with euclidian distance")
corr_dists<-as.dist(1-cor(t(GeneData))) # TODO: Dobbeltsjekk denne.
plot(hclust(corr_dists, method="complete"), main="Complete linkage with correlation-based distance")
plot(hclust(corr_dists, method="single"), main="Single linkage with correlation-based distance")
plot(hclust(corr_dists, method="average"), main="Average linkage with correlation-based distance")
```


# Task 5d

## TODO: Cluster into groups, which performs best?
```{r task5d}
cutree(hclust(euc_dists, method="complete"), k=2)
cutree(hclust(euc_dists, method="single"), k=2)
cutree(hclust(euc_dists, method="average"), k=2)
cutree(hclust(corr_dists, method="complete"), k=2)
cutree(hclust(corr_dists, method="single"), k=2)
cutree(hclust(corr_dists, method="average"), k=2)
```

# Task 5e

## i)
```{r task5ei}
GeneData.pca<-prcomp(GeneData, center=TRUE, scale=TRUE)
GeneData.pca$x[,1]
GeneData.pca$x[,2]

plot(GeneData.pca$x[,1], GeneData.pca$x[,2], col=c(rep(1, 20), rep(2, 20)))
```

## ii)
```{r task5eii}
summary(GeneData.pca)
```
The 5 first principal components explains 21.097% of the total variance.

# Task 5f

```{r task5f}
summary(GeneData.pca)
rot_1 = GeneData.pca$rotation[,1]
rot_1[order(abs(rot_1), decreasing = TRUE)][1:50]
```
