---
title: "CompulsoryExercise_1"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Import neccessary packages

```{r libraries, message=FALSE, include=TRUE, eval=TRUE}
library(ggplot2)
library(caret)
library(MASS)
library(class)
library(pROC)
library(knitr)
library(dplyr)
library(ggplot2)
library(MASS)
library(boot)
```


# Task 1

## A)

$\text{E}[\widetilde{\boldsymbol{\beta}}]=\text{E}[(\mathbf{X}^T\mathbf{X}+\lambda \mathbf{I})^{-1}\mathbf{X}^T{\bf Y}]=(\mathbf{X}^T\mathbf{X}+\lambda \mathbf{I})^{-1}\text{E}[\mathbf{X}^T{\bf Y}]=(\mathbf{X}^T\mathbf{X}+\lambda \mathbf{I})^{-1}\mathbf{X}^T\text{E}[{\bf Y}]=(\mathbf{X}^T\mathbf{X}+\lambda \mathbf{I})^{-1}\mathbf{X}^T\text{E}[\mathbf{X}\boldsymbol{\beta}+\varepsilon]=(\mathbf{X}^T\mathbf{X}+\lambda \mathbf{I})^{-1}\mathbf{X}^T\mathbf{X}\boldsymbol{\beta}$

$Cov(\hat{\boldsymbol\beta})=Cov((X^T X+\lambda\mathbf{I})^{-1}X^T Y)=(X^TX+\lambda\mathbf{I})^{-1}X^T Cov(Y)((X^TX+\lambda\mathbf{I})^{-1}X^T)^T=(X^TX)^{-1}X^T \sigma^2  I ((X^TX+\lambda\mathbf{I})^{-1}X^T)^T=\sigma^2 (X^TX+\lambda\mathbf{I})^{-1} \\$

## D)

Load the data.
```{r data, include=TRUE, message=FALSE, eval=TRUE}
id <- "1X_8OKcoYbng1XvYFDirxjEWr7LtpNr1m"  # google file ID
values <- dget(sprintf("https://docs.google.com/uc?id=%s&export=download", id))
X = values$X
x0 = values$x0
beta = values$beta
sigma = values$sigma
```


Display squared bias.
```{r squared bias, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
bias = function(lambda, X, x0, beta) {
  p = ncol(X)
  value = (t(x0) %*% solve((t(X) %*% X + lambda * diag(p))) %*% t(X) %*% X %*% beta - t(x0) %*% beta ) ^ 2
  return(value)
}
lambdas = seq(0, 2, length.out = 500)
BIAS = rep(NA, length(lambdas))
for (i in 1:length(lambdas)) BIAS[i] = bias(lambdas[i], X, x0, beta)
dfBias = data.frame(lambdas = lambdas, bias = BIAS)
ggplot(dfBias, aes(x = lambdas, y = bias)) + geom_line(color = "red") + xlab(expression(lambda)) +
  ylab(expression(bias^2))
```

From the figure above, it is clear that the bias increases when the lambda increases.
This is natural, as the lambda is regularising hyperparameter: larger values of lambda
constrains the $\beta$ values more. We do also see that the squared bias starts to decreas when $\lambda$ is approximately $0.1 < \lambda < 0.45$. The cause for this is that the bias is actually negative when $\lambda < 0.45$, so the bias is actually increasing
for that interval thus the squared value is decreasing.

## E)

```{r variance, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
variance = function(lambda, X, x0, sigma) {
  p = ncol(X)
  inv = solve(t(X) %*% X + lambda * diag(p))
  value = sigma * sigma * t(x0) %*% solve(t(X) %*% X + lambda * diag(p)) %*% t(X) %*% X %*% solve(t(X) %*% X + lambda * diag(p)) %*% x0
  return(value)
}
lambdas = seq(0, 2, length.out = 500)
VAR = rep(NA, length(lambdas))
for (i in 1:length(lambdas)) VAR[i] = variance(lambdas[i], X, x0, sigma)
dfVar = data.frame(lambdas = lambdas, var = VAR)
ggplot(dfVar, aes(x = lambdas, y = var)) + geom_line(color = "green4") + xlab(expression(lambda)) +
  ylab("variance")
```

From the figure above, it is clear that the variance decreases when the lambda increases.
This is natural, as the lambda is regularising hyperparameter: larger values of lambda
constrains the $\beta$ values more, causing less variance.


## F)

```{r expected mse, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}

exp_mse = BIAS + VAR + sigma * sigma
lambdas[which.min(exp_mse)]

dfAll = data.frame(lambda = lambdas, bias = BIAS, var = VAR, exp_mse = exp_mse)
ggplot(dfAll) + geom_line(aes(x = lambda, y = exp_mse), color = "blue") +
  geom_line(aes(x = lambda, y = bias), color = "red") +
  geom_line(aes(x = lambda, y = var), color = "green4") +
  xlab(expression(lambda)) +
  ylab(expression(E(MSE))
)
```

From the plot we see that the value of $\lambda$ that minimizes the expected mse is 0.993988.

# Problem 2

## A)

```{r problem 2 A, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
# read file
id <- "1yYlEl5gYY3BEtJ4d7KWaFGIOEweJIn__" # google file ID
d.corona <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download", id),header=T)
summary(d.corona)

# Number of deceased
nrow(filter(d.corona, d.corona$deceased == "1"))

#Number of non-deceased
nrow(filter(d.corona, d.corona$deceased == "0"))

# Number of males and females for each country
d.corona %>%
  group_by(country, sex) %>%
  summarise(amount = n()) %>%
  arrange(desc(amount))


# The number of deceased and non-deceased for each sex
d.corona %>%
  group_by(deceased, sex) %>%
  summarise(amount = n()) %>%
  arrange(desc(amount)) 

# The number of deceased and non-deceased in France, separate for each sex.
filter(d.corona, d.corona$country == "France") %>%
  group_by(deceased, sex) %>%
  summarise(amount = n()) %>%
  arrange(desc(amount)) 
``` 

## B)

```{r problem 2 glm, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
set.seed(4268)
train_ID = sample(1:nrow(d.corona), nrow(d.corona)/(3/2))
train_data = d.corona[train_ID, ]
test_data = d.corona[-train_ID, ]


model <- glm(deceased ~ age + country + sex, family = binomial, data=train_data)
summary(model)
```

### i). What is the probability to die of covid for a male age 75 living in Korea?
```{r problem 2 prob, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
data_point <- data.frame("age" = 75, "sex" = "male","country" = "Korea")
predict(model, newdata = data_point, type = "response")
```


### ii). Is there evidence that males have higher probability to die than females?
Yes, the summary of the regression model shows that there are a higher probability for males to die than females.
As we can see from the summary of the model, the p-value are significantly close to zero. Therefore we can reject the null hypothesis that the coefficient is equalt to zero. 
We can then conclude that the coefficient for male are a meaningful addition to the model and changes in the predictor's value are related to changes in the response variable..
  
### iii). Is there evidence that the country of residence has an influence on the probability to decease?
Yes, there is evidence that the country of residence has an impact on the probability to decease. There is a big difference between the p-value for the coefficients of Korea, Japan, and Indonesia. 
Indonesia has a much higher p-value than the rest. Since the p-value is so high, we can not reject the null hypothesis. The null hypothesis tests if the coefficient is equal to zero. 
In other words, if the coefficients has small impact on the model.
This is evidence that for France and Indonesia, the country of residence does not impact the probability of decease that much. 
While for Korea and Japan it has a bigger influence. 

### iv). Quantify how the odds to die changes when someone with otherwise identical covariates is 10 years older than another person.
```{r problem 2 odds, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
summary(model)
exp(10*coefficients(model)[2])
```


## C)

### i). Is age a greater risk factor for males than for females?
```{r problem 2 greater risk, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
fit <- glm(deceased ~ age * sex + country, data=d.corona)
summary(fit)
anova(fit, test="Chisq")
```
The F-test shows us that there are no evidence that the interaction term between age and sex is needed. The p-values is not statistically significant, and we can therefore not reject the null hypothesis. 
We can therefore conclude that age is not a greater risk for males than for females. 

### ii). Is age a greater risk factor for the French population than for the Indonesian population?

```{r problem 2 greater risk country, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
fit.lm <- glm(deceased ~ age * country + sex, data=d.corona)
summary(fit.lm)
anova(fit.lm, test = "Chisq")
```
As the F-test shows evidence that the interaction term between country and age does matter, and the p-values is statistically significant. But the coefficient between age:countryindonesia and intercept (France) is quite low, that it won't make a huge impact on the risk difference between the countries. Therefore we can conclude that the age is not a greater risk for the French population than for the Indonesian population.



## D)

```{r problem 2 lda, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
lda_model <- lda(deceased ~ age + country + sex, data=d.corona)
lda_pred <- predict(lda_model, newdata=test_data[-1])

create_confusion_matrix <- function(pred, target) {
  confMat <- table(pred, target)
  colnames(confMat) <- c("PRED FALSE", "PRED TRUE")
  row.names(confMat) <- c("TARGET FALSE", "TARGET TRUE")
  return(confMat)
}

conf_matrix <- create_confusion_matrix(unlist(lda_pred[1]), test_data$deceased)
sum(conf_matrix)
# Null rate
(conf_matrix[1,2] + conf_matrix[2,2]) / sum(conf_matrix) 
```
### i). 
**The "null rate" for misclassification is 5.22%, because this is the proportion of deaths among all cases in the dataset.**
False

### ii).
**LDA is not a very useful method for this dataset.**
False

### iii). 
**LDA has a specificity of 1.**
```{r problem 2 specificity, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
conf_matrix[1,1] / (conf_matrix[1,1] + conf_matrix[1,2])
```
False

### iv). 
**QDA has a lower sensitivity to classify deceased compared to LDA.**
```{r problem 2 qda, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
qda.fit <- qda(deceased ~ age + country + sex, data=d.corona)
qda_pred <- predict(qda.fit, newdata=test_data[-1])
qda_conf <- create_confusion_matrix(unlist(qda_pred[1]), test_data$deceased)
conf_matrix
# Sensitivity for LDA
lda_sens <- conf_matrix[2,1] / (conf_matrix[2,1] + conf_matrix[2,2])
# Sensitivity for QDA
qda_sens <- qda_conf[2,1] / (sum(qda_conf[2,]))

qda_sens < lda_sens
```
False


# Task 3


```{r data problem 3, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
# read file
id <- "1i1cQPeoLLC_FyAH0nnqCnnrSBpn05_hO"  # google file ID
diab <- dget(sprintf("https://docs.google.com/uc?id=%s&export=download", id))

t = MASS::Pima.tr2
train = diab$ctrain
test = diab$ctest
```

## A)

### i)
$P(y_i = 1| \mathbf{X}={\mathbf{x}}_i) = p_i = \frac{e^{\beta_0 + \beta_1x_{i1} + \beta_2 x_{i2} + \dots + \beta_7 x_{i7}}}{ 1+ e^{\beta_0 + \beta_1x_{i1} + \beta_2 x_{i2} + \dots + \beta_7 x_{i7}}}$

$1-p_i=\frac{1+e^{\beta_0 + \beta_1x_{i1} + \beta_2 x_{i2} + \dots + \beta_7 x_{i7}}-e^{\beta_0 + \beta_1x_{i1} + \beta_2 x_{i2} + \dots + \beta_7 x_{i7}}}{ 1+ e^{\beta_0 + \beta_1x_{i1} + \beta_2 x_{i2} + \dots + \beta_7 x_{i7}}}= \frac{1}{ 1+ e^{\beta_0 + \beta_1x_{i1} + \beta_2 x_{i2} + \dots + \beta_7 x_{i7}}}$

$\frac{p_i}{1-p_i}=\frac{\frac{e^{\beta_0 + \beta_1x_{i1} + \beta_2 x_{i2} + \dots + \beta_7 x_{i7}}}{ 1+ e^{\beta_0 + \beta_1x_{i1} + \beta_2 x_{i2} + \dots + \beta_7 x_{i7}}}}{\frac{1}{ 1+ e^{\beta_0 + \beta_1x_{i1} + \beta_2 x_{i2} + \dots + \beta_7 x_{i7}}}}=e^{\beta_0 + \beta_1x_{i1} + \beta_2 x_{i2} + \dots + \beta_7 x_{i7}}$

$log(\frac{p_i}{1-p_i})=log(e^{\beta_0 + \beta_1x_{i1} + \beta_2 x_{i2} + \dots + \beta_7 x_{i7}})=\beta_0 + \beta_1x_{i1} + \beta_2 x_{i2} + \dots + \beta_7 x_{i7}$

### ii)
```{r logistic regression 3, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
logReg = glm(diabetes ~ ., data = train, family = "binomial")
summary(logReg)


cutOff = 0.5
pred_log_reg <- predict(logReg, newdata = test[-1], type="response")
conf_mat = create_confusion_matrix(pred_log_reg>cutOff, test$diabetes)
conf_mat

print("The sensitivity is:")
conf_mat[2,2]/(conf_mat[2,1]+conf_mat[2,2])
print("The specificity is:")
conf_mat[1,1]/(conf_mat[1,2]+conf_mat[1,1])
```


## B)

### i)
$\pi_k$ denotes the prior probability that an observation belongs to the k'th class. In this case $\pi_0$ and $\pi_1$ is the proportion of people in the training set without and with diabets, respectively.

$\mu_k$ is a class specific mean vector. In the diabetes classification problem, $\mu_k$ is a vector of means of all the predictors (age, ped, bmi, skin, bp, glu, npreg).

$\Sigma$ is a covariance matrix, that is common to all classes. It is the pxp covariance matrix of $X$.

$f_k(x)$ is the density function of $X$ for the k'th class. That is, it has a large value if there is a high probability that
an observation in the kth class has $X\approx x$.

### ii)
```{r linear-/quadretic discriminant analysis, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
lda_model <- lda(diabetes ~ ., data=train)
pred_lda <- predict(lda_model, newdata=test[-1])
conf_mat = create_confusion_matrix(unlist(pred_lda[1]), test$diabetes)
conf_mat
# With cutOff = 0.5: pred[1]
# Posterior probabilities: pred[2]

qda_model <- qda(diabetes ~ ., data=train)
pred_qda <- predict(qda_model, newdata=test[-1])
conf_mat = create_confusion_matrix(unlist(pred_qda[1]), test$diabetes)
conf_mat

```
QDA is like LDA except that every class has its own covariance matrix, $\Sigma_k$, and not a common one, $\Sigma$ as is the case for
LDA.

## C)

### i)
The KNN classifier classifies a new observation by first finding its k closest points in the training data,
then it estimates the conditional probability for class j as the fraction of the k points that are of class j.
There are different metrics for "closeness". Exampel of common ones are: euclidian distance, cosine distance and manhatan distance.
More formally:

$Pr(\mathbf{Y}=j|\mathbf{X}=\mathbf{x}_0)=\frac{1}{K}\sum_{i\epsilon N} I(\mathbf{y}_i=j)$

where $I(x)$ is 1 if $\mathbf{x}$ is true and 0 if $\mathbf{x}$ is false and $N$ is the set of k closest points.
The final classification for the new variable is the most occuring class among its neighbours.

### ii)
It is possible to choose the tuning parameter, k, by using cross validation and see which value of k the
validation loss is the lowest.


### iii)
```{r knn, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
pred_knn <- knn(train = train[-1], test=test[-1], cl=unlist(train[1]), k=25, prob=TRUE)

convert <- function(pred, prob) {
  # Invert probabilities: the probabilites from knn(...) are the success probabilities
  # for the predicted class, thus P(y=2) = 1 - P(y=1) when we predicted 1.
  inv_prob = c()
  for(pos in 1:length(prob)) {
    inv_prob[pos] <- ifelse(as.numeric(pred[pos])==2, prob[pos], 1-prob[pos])
  }
  return(inv_prob)
}
prob_knn_adj <- convert(pred_knn, attributes(pred_knn)$prob)

conf_mat = create_confusion_matrix(unlist(pred_knn), test$diabetes)
conf_mat
print("The sensitivity is:")
conf_mat[2,2]/(conf_mat[2,1]+conf_mat[2,2])
print("The specificity is:")
conf_mat[1,1]/(conf_mat[1,2]+conf_mat[1,1])
```

## D)
```{r roc, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
roc.log_reg <- roc(response = test$diabetes, predictor = pred_log_reg, plot=FALSE)
roc.lda <- roc(response = test$diabetes, predictor = pred_lda$posterior[,2], plot=FALSE)
roc.qda <- roc(response = test$diabetes, predictor = pred_qda$posterior[,2], plot=FALSE)
roc.knn <- roc(response = test$diabetes, predictor = prob_knn_adj, plot=FALSE)
auc(roc.log_reg)
auc(roc.lda)
auc(roc.qda)
auc(roc.knn)

plot(roc.log_reg, main="ROC", col="red")
plot(roc.lda, add=TRUE, col="green")
plot(roc.qda, add=TRUE, col="blue")
plot(roc.knn, add=TRUE, col="black")
legend('topright', c("log_reg","lda", "qda", "knn"),
       lty=1, col=c('red', 'green', 'blue',' black'), bty='n', cex=.75)
```

From the calculated AUC we see that the Linear Discriminant Analysis performs the best.
If the task was to create an interpretable model, we would have chosen the logistic regression as it
it more interpretable than the other models presented in this case. Additionally it performed second best,
not far behind Linear Discriminant Analysis.


# Problem 4

## A)
Show that for the linear regression model $Y=X\beta+\epsilon$ the LOOCV statistic can be computed by the following formula

$CV = \frac{1}{N}\sum^N_{i=1}(\frac{y_i - \hat{y}_i}{1-h_i})^2$, where $h_i=X^T_i(X_TX)^{-1}x_i$, and $x^T_i$ is the ith row of X.

The estimate of $\beta$ is given by
$\hat{\beta_i}=(X^T_{(-i)}X_{(-i)})X_{(-i)}Y$

This gives us that $y_i-\hat{y}_i = y_i - x^T_{(-i)}\hat{\beta_i}$

We know that $X^T_{(-i)}X_{(-i)}=(X^TX−x_{i}x^T_i)$
We can then use the Sherman Morrison formula, to find $(X^T_{(-1)}X_{(-1)})^{-1} = (X^TX)^{−1}+\frac{(X^TX)^{−1}x_{i}x^T_{i}(X^TX)^{−1}}{1−h_i}$

We can use this to find $\hat{\beta}$

$$\hat{\beta}_i 
= ((X^TX)^{−1}+\frac{(X^TX)^{−1}x_{i}x^T_{i}(X^TX)^{−1}}{1−h_i})(X^TY-x_iy_i)$$
$$
= \hat{\beta} - (\frac{(X^TX)^{−1}x_{i}}{1−h_i})(y_i(1-h_i)-x^T_i\hat{\beta}+h_iy_i)
=\hat{\beta}-(X^TX)^{-1}x_i\frac{y_i - \hat{y}_i}{1-h_i}
$$

Therefore we get, 

$$
y_i - \hat{y}_i = y_i-x^T_i\hat{\beta} = y_i-x^T_i(\hat{\beta}-(X^TX)^{-1}x_i\frac{y_i - \hat{y}_i}{1-h_i}) 
$$
$$y_i - \hat{y}_i \ h_i \frac{y_i - \hat{y}_i}{1-h_i}
= \frac{y_i - \hat{y}_i}{1-h_i}
$$
This concludes the proof and shows that $CV = \frac{1}{N}\sum^N_{i=1}(\frac{y_i - \hat{y}_i}{1-h_i})^2$


## B)

1. False
2. True
3. ?
4. False

# Problem 5
## A) 
```{r r_squared, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
id <- "19auu8YlUJJJUsZY8JZfsCTWzDm6doE7C" # google file ID
d.bodyfat <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download", id),header=T)

rsquared <- function(data, indices) {
  d <- data[indices,] # select samples
  fit <- lm(bodyfat ~ age + weight + bmi, data = d)
  return(summary(fit)$r.square)
}

rsquared(d.bodyfat)
```

The R^2 for a linear regression model is 0.5803

## B)

### i)
```{r problem 5 bootstrapping, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
set.seed(4268)

# bootstrapping with 1000 replications
results <- boot(data=d.bodyfat, statistic=rsquared,
                R=1000)
```
### ii)

```{r problem 5 bootstrap plot, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
# view results
plot(results)

```

### iii)
```{r problem 5 std, include=TRUE, message=FALSE, eval=TRUE, tidy=TRUE}
# standard error
apply(results$t, 2, sd)

# get 95% confidence interval
boot.ci(results, type="bca")
```

### iv)

This confidence interval tells us that there are a 95% probability that the interval will contain the true R2 value. 